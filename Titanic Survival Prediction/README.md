# ğŸš¢ **PredicciÃ³n de Supervivencia en el Titanic**  
### ğŸŒŸ Proyecto de ClasificaciÃ³n con Python  

Este proyecto utiliza el famoso dataset del Titanic para predecir la supervivencia de los pasajeros mediante algoritmos de clasificaciÃ³n.  

---

## ğŸ” **DescripciÃ³n del Proyecto**  
El anÃ¡lisis tiene como objetivo explorar, preprocesar y construir modelos de clasificaciÃ³n para predecir si un pasajero sobreviviÃ³ o no al desastre del Titanic. Se emplean herramientas como Python, bibliotecas de anÃ¡lisis de datos y aprendizaje automÃ¡tico, y tÃ©cnicas de visualizaciÃ³n.  

---

## ğŸ—‚ï¸ **Estructura del Proyecto**  
1. **ExploraciÃ³n de Datos (EDA)**  
   - ğŸ“Š AnÃ¡lisis estadÃ­stico y visualizaciÃ³n de datos.  
   - ğŸ•µï¸â€â™‚ï¸ IdentificaciÃ³n de valores nulos, duplicados y outliers.  
   - ğŸ”— RelaciÃ³n entre variables y la variable objetivo (`Survived`).  

2. **Preprocesamiento de Datos**  
   - ğŸ› ï¸ ImputaciÃ³n de valores faltantes (mediana para numÃ©ricos, moda para categÃ³ricos).  
   - ğŸ—‘ï¸ EliminaciÃ³n de columnas irrelevantes como `PassengerId`, `Name`, `Ticket` y `Cabin`.  
   - ğŸ“ Escalado de variables numÃ©ricas y codificaciÃ³n de variables categÃ³ricas (`Sex` y `Embarked`).  

3. **Modelado y EvaluaciÃ³n**  
   - âš™ï¸ **Modelos utilizados:**  
     - ğŸŒ² Ãrbol de DecisiÃ³n (DecisionTreeClassifier)  
     - ğŸ“‰ Naive Bayes Gaussiano (GaussianNB)  
     - ğŸ¤ K-Vecinos MÃ¡s Cercanos (KNeighborsClassifier)  
     - ğŸš€ XGBoost (XGBClassifier)  
   - ğŸ§® **MÃ©tricas de evaluaciÃ³n:**  
     - ğŸ“ƒ Reporte de clasificaciÃ³n  
     - ğŸ—‚ï¸ Matriz de confusiÃ³n  
     - ğŸ“Š PrecisiÃ³n, sensibilidad y F1-Score  
 
## ğŸ“Œ **Conclusiones**  

1. **Impacto del GÃ©nero en la Supervivencia**  
   - ğŸ‘©â€ğŸ¦± **Las mujeres tienen una tasa de supervivencia mÃ¡s alta** que los hombres. Esto se debe probablemente a la polÃ­tica de evacuaciÃ³n, donde se priorizaba a las mujeres y niÃ±os. La variable `Sex` se mostrÃ³ muy relevante en los modelos de predicciÃ³n.

2. **Clase de Pasajero y Supervivencia**  
   - ğŸ° **Los pasajeros de primera clase tienen una probabilidad de supervivencia significativamente mayor** en comparaciÃ³n con los de segunda y tercera clase. Esto indica que los pasajeros de clase alta probablemente tenÃ­an mÃ¡s acceso a los botes salvavidas y otras medidas de evacuaciÃ³n.

3. **Edad y Supervivencia**  
   - ğŸ‘¶ **Los niÃ±os tienen una tasa de supervivencia mÃ¡s alta** que los adultos. Esto sugiere que se dio preferencia a los niÃ±os durante el proceso de evacuaciÃ³n, tal vez debido a la polÃ­tica de "mujeres y niÃ±os primero".

4. **Impacto del Embarque**  
   - ğŸš¢ **El puerto de embarque (variable `Embarked`) tiene un impacto menor en la supervivencia**, aunque algunos modelos muestran una leve correlaciÃ³n. En general, los pasajeros embarcados en `Cherbourg` tuvieron una tasa de supervivencia mÃ¡s alta que los de `Southampton`.

5. **Estrategias de Preprocesamiento Efectivas**  
   - ğŸ› ï¸ **El preprocesamiento de los datos, como la imputaciÃ³n de valores faltantes y la codificaciÃ³n de variables categÃ³ricas**, permitiÃ³ que los modelos trabajaran de manera eficiente. Imputar las edades con la mediana fue una estrategia que mejorÃ³ la precisiÃ³n de los modelos.

6. **DesempeÃ±o de Modelos**  
   - ğŸŒ² **Ãrbol de DecisiÃ³n**: El modelo mÃ¡s interpretable, pero con cierto sobreajuste.  
   - ğŸ“‰ **Naive Bayes Gaussiano**: RÃ¡pido y eficiente, pero con menor precisiÃ³n comparado con otros modelos.  
   - ğŸ¤ **K-Vecinos MÃ¡s Cercanos (KNN)**: Buen desempeÃ±o, aunque mÃ¡s lento para grandes volÃºmenes de datos.  
   - ğŸš€ **XGBoost**: El modelo mÃ¡s robusto, mostrando la mayor precisiÃ³n, especialmente en la clasificaciÃ³n binaria de supervivientes y no supervivientes.

7. **OptimizaciÃ³n de Modelos**  
   - ğŸ”§ **El ajuste de hiperparÃ¡metros** en el modelo XGBoost, como el nÃºmero de Ã¡rboles (`n_estimators`) y la tasa de aprendizaje (`learning_rate`), ayudÃ³ a mejorar la precisiÃ³n, destacÃ¡ndose en comparaciÃ³n con otros modelos probados.

---

## ğŸ› ï¸ **Requisitos**  
- **Python 3.11**  
- **Bibliotecas:**  
  - ğŸ `numpy`, `pandas`, `matplotlib`, `seaborn`  
  - ğŸ¤– `scikit-learn`, `xgboost`  

---

## ğŸš€ **Instrucciones de EjecuciÃ³n**  
1. Instalar las dependencias:  
   ```bash
   pip install numpy pandas matplotlib seaborn scikit-learn xgboost
2. Descargar el dataset de entrenamiento y el de prueba localizados en la carpeta
3. Ejecutar el archivo del proyecto en un entorno como Jupyter Notebook, VSCode o Google Colab.
